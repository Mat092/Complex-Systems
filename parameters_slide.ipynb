{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This notebook contains the code to perfrmos multiple overfitting in CIFAR10 \n",
    "as a function of the numbers of parameters\n",
    "'''\n",
    "\n",
    "# import and definitions \n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Flatten, Input\n",
    "from tensorflow.keras.layers import Conv2D, GlobalAveragePooling2D\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplolib.pyplot as plt\n",
    "\n",
    "class LossHistory(tf.keras.callbacks.Callback):\n",
    "\n",
    "  def on_train_begin(self, logs={}):\n",
    "    self.losses = []\n",
    "    self.accuracies = []\n",
    "\n",
    "  def on_batch_end(self, batch, logs={}):\n",
    "    self.losses.append(logs.get('loss'))\n",
    "    self.accuracies.append(logs.get('accuracy'))\n",
    "\n",
    "  def on_epoch_end(self, epoch, logs={}):\n",
    "    import pandas as pd\n",
    "\n",
    "    df = pd.DataFrame({'accuracies' : self.accuracies,\n",
    "                       'losses'     : self.losses})\n",
    "\n",
    "    df.to_csv('saved_models/cifar100_callback_noconv.csv', header=True, float_format='%g')\n",
    "\n",
    "    \n",
    "def create_model(n_filters, input_shape, hidden_layers=2):\n",
    "\n",
    "  model = Sequential()\n",
    "  model.add(Input(shape=input_shape))\n",
    "\n",
    "  for _ in range(hidden_layers):\n",
    "    model.add(Conv2D(filters=n_filters, kernel_size=(3,3), activation='relu', padding='same'))\n",
    "\n",
    "  model.add(Conv2D(filters=10, kernel_size=(3,3), activation='relu', padding='same'))\n",
    "  model.add(GlobalAveragePooling2D(data_format='channels_last'))\n",
    "  model.add(Activation(activation='softmax'))\n",
    "\n",
    "  opt = tf.keras.optimizers.SGD(learning_rate=0.01)\n",
    "\n",
    "  model.compile(loss='categorical_crossentropy',\n",
    "                optimizer=opt,\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "  return model\n",
    "\n",
    "\n",
    "def train_model_on_parameters(X, y, model, epochs, batch_size):\n",
    "\n",
    "  callback = LossHistory()\n",
    "\n",
    "  history = model.fit(X, y,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=False,\n",
    "              callbacks=[callback])\n",
    "\n",
    "  return history, callback\n",
    "\n",
    "\n",
    "def train_model_loop (X, y, par_range=range(1, 32, 4), epochs=10, batch_size=100) :\n",
    "\n",
    "  histories = []\n",
    "  callbacks = []\n",
    "\n",
    "  for num_filters in par_range :\n",
    "\n",
    "    print(num_filters)\n",
    "\n",
    "    model = create_model(num_filters, input_shape)\n",
    "\n",
    "    history, callback = train_model_on_parameters(X, y, model, epochs, batch_size)\n",
    "\n",
    "    histories.append(history.history)\n",
    "    callbacks.append({'accuracy' : callback.accuracies,\n",
    "                      'loss'     : callback.losses})\n",
    "\n",
    "  return histories, callbacks\n",
    "\n",
    "\n",
    "def num_parameters (n_filt):\n",
    "  return 9 * n_filt * (13 + n_filt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset preprocess and constants definition\n",
    "\n",
    "batch_size  = 32\n",
    "num_classes = 10\n",
    "\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "model_name = 'saved_models/keras_cifar10_trained_model.h5'\n",
    "\n",
    "# The data, split between train and test sets:\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# Be sure data are float and in range [0., 1.]\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test  = x_test.astype('float32')  / 255.\n",
    "\n",
    "# Input image dimensions\n",
    "img_rows, img_cols, channels = 32, 32, 3\n",
    "\n",
    "# CHannel last format\n",
    "x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, channels)\n",
    "x_test  = x_test.reshape( x_test.shape[0] , img_rows, img_cols, channels)\n",
    "input_shape = (img_rows, img_cols, channels)\n",
    "\n",
    "# Convert class vectors to binary class matrices.\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test  = tf.keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Train model, it takes quite a while, and saving\n",
    "\n",
    "histories, callbacks = train_model_loop(x_train, y_train, range(1, 100, 4), epochs=16, batch_size=100)\n",
    "\n",
    "histfile = 'saved_models/hist_cifar10_parameters'\n",
    "callfile = 'saved_models/call_cifar10_parameters'\n",
    "\n",
    "dfh = pd.DataFrame(histories)\n",
    "dfc = pd.DataFrame(callbacks)\n",
    "\n",
    "dfh.to_csv(histfile, header=True, float_format='%g')\n",
    "dfc.to_csv(callfile, header=True, float_format='%g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting #"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
